{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "75e7c314",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Instalación de paquetes\n",
    "!pip install keras\n",
    "!pip install tensorflow\n",
    "\n",
    "# Importaciones\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Conv2D, MaxPooling2D, Flatten, Dense\n",
    "from keras.preprocessing.image import ImageDataGenerator\n",
    "import numpy as np\n",
    "from keras.preprocessing import image\n",
    "\n",
    "# Construcción del modelo\n",
    "classifier = Sequential()\n",
    "\n",
    "# Capa 1\n",
    "classifier.add(Conv2D(filters=32, kernel_size=(3,3), input_shape=(64,64,3), activation=\"relu\"))\n",
    "classifier.add(MaxPooling2D(pool_size=(2,2)))\n",
    "\n",
    "# Capa 2\n",
    "classifier.add(Conv2D(filters=32, kernel_size=(3,3), activation=\"relu\"))\n",
    "classifier.add(MaxPooling2D(pool_size=(2,2)))\n",
    "\n",
    "classifier.add(Flatten())\n",
    "\n",
    "classifier.add(Dense(units=128, activation=\"relu\"))\n",
    "classifier.add(Dense(units=1, activation=\"sigmoid\"))\n",
    "\n",
    "classifier.compile(optimizer=\"adam\", loss=\"binary_crossentropy\", metrics=[\"accuracy\"])\n",
    "\n",
    "# Generadores de datos\n",
    "train_datagen = ImageDataGenerator(\n",
    "    rescale=1./255,\n",
    "    shear_range=0.2,\n",
    "    horizontal_flip=True\n",
    ")\n",
    "\n",
    "test_datagen = ImageDataGenerator(rescale=1./255)\n",
    "\n",
    "train_route = 'C:/Users/Usuario/Desktop/Máster IMF/Máster_IMF/Alexa'  # Ruta de entrenamiento\n",
    "test_route = 'C:/Users/Usuario/Desktop/Máster IMF/Máster_IMF/Alexa'  # Ruta de prueba\n",
    "\n",
    "training_dataset = train_datagen.flow_from_directory(\n",
    "    train_route,\n",
    "    target_size=(64,64),\n",
    "    batch_size=32,\n",
    "    class_mode=\"binary\"\n",
    ")\n",
    "\n",
    "test_dataset = test_datagen.flow_from_directory(\n",
    "    test_route,\n",
    "    target_size=(64,64),\n",
    "    batch_size=32,\n",
    "    class_mode=\"binary\"\n",
    ")\n",
    "\n",
    "classifier.fit(\n",
    "    training_dataset,\n",
    "    steps_per_epoch=50,\n",
    "    epochs=10,\n",
    "    validation_data=test_dataset,\n",
    "    validation_steps=50\n",
    ")\n",
    "\n",
    "# Predicción de una imagen individual\n",
    "single_dog = 'C:/Users/Usuario/Desktop/Máster IMF/Máster_IMF/Alexa/testunosolo/dog.3901.jpg'  # Ruta de la imagen del perro\n",
    "single_cat = 'C:/Users/Usuario/Desktop/Máster IMF/Máster_IMF/Alexa/testunosolo/cat.3993.jpg'  # Ruta de la imagen del gato\n",
    "\n",
    "# Función para hacer una predicción\n",
    "def predict_image(image_path):\n",
    "    test_image = image.load_img(image_path, target_size=(64, 64))\n",
    "    test_image = image.img_to_array(test_image)\n",
    "    test_image = np.expand_dims(test_image, axis=0)\n",
    "    result = classifier.predict(test_image)\n",
    "    if result[0][0] == 1:\n",
    "        return 'dog'\n",
    "    else:\n",
    "        return 'cat'\n",
    "\n",
    "# Predicción para un perro y un gato\n",
    "prediction_dog = predict_image(single_dog)\n",
    "prediction_cat = predict_image(single_cat)\n",
    "\n",
    "print(\"Predicción para el perro:\", prediction_dog)\n",
    "print(\"Predicción para el gato:\", prediction_cat)\n",
    "\n",
    "# Para mejorar el modelo se deben etiquetar mayor número de fotos (unas 1000 para gatos e igual para perros)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e43b449a",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
